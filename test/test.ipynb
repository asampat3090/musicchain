{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pydub\n",
    "import pypianoroll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_datapath_midi = 'roja-ar-rahman-melody.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIClip:\n",
    "    \"\"\"MIDI clip object which reads from a MIDI file andi \"\"\"\n",
    "    def __init__(self, filepath:str) -> None: \n",
    "        \"\"\"\n",
    "        filepath (str): Path to the MIDI file (.mid).\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        # self.midi = pydub.MIDI(self.filepath)\n",
    "        # self.duration = self.midi.duration_seconds\n",
    "        # self.mono = True if self.tensor.shape[0] == 1 else False\n",
    "\n",
    "    def pianoroll(self, resolution: int = 24, type=\"binary\", tensor_type=torch.float32) -> torch.Tensor:\n",
    "        \"\"\"Converts a MIDI file to a piano roll representation. \n",
    "\n",
    "        The piano roll representation is a common way to represent music data.\n",
    "        It consists of a two-dimensional matrix where the rows represent time steps \n",
    "        and the columns represent pitches (and special symbols in certain variations). The time steps also depend on the model and level of granularity desired. For coherence, many ML models filter inputs to 4/4 time signatures and use sixteenth notes as a single time step (16 steps / bar).  \n",
    "        The entries of the matrix are considered as non-negative. \n",
    "\n",
    "        1) Binary: One example is when the entries are binary, indicating whether a note is played at a given time step and pitch. \n",
    "\n",
    "        X ∈ {0, 1}^(h×w) where `h` is the number of pitches and `w` is the number of time steps.\n",
    "\n",
    "        *NOTE: velocity and complex time signature differences are IGNORED in this version!*\n",
    "\n",
    "        2) Velocity: Another variation on this form also considers the velocity of the note. In this case, the entries are integers in the range of 0-127 indicating the velocity of the note played at a given time step and pitch. In this first section, we will talk about the models that look at only the binary piano roll representation, but will revisit the velocity in the next section.\n",
    "\n",
    "        X ∈ [0,127]^(h×w)\n",
    "\n",
    "        *NOTE: The number of pitches in a MIDI file is 128, however the dimension of `h` may be reduced to narrow the range of notes to a specific instrument (e.g. 88 keys in a piano) or can be expanded to include silence or rests (e.g. 129/130 or 89/90).  \n",
    "\n",
    "        Args:\n",
    "        resolution (int, optional): Number of ticks per beat (default: 24).\n",
    "        type (str, optional): type of pianoroll: binary - 0 or 1 , velocity - 0-127 (default: \"binary\")\n",
    "        tensor_type (torch.Type, optional): Tensor type can be updated for different hardware configs (default: torch.float32)\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Piano roll representation of the MIDI file in tensor fp32 format (128 x T) \n",
    "\n",
    "        Usage: \n",
    "        > midi_obj = MIDIClip(midi_path)\n",
    "        > midi_obj.piano_roll\n",
    "        > [[1,..,0,...,0],\n",
    "           ...,\n",
    "           [0,...,1,...,0],\n",
    "           ...,\n",
    "           [0,...,0,...,1]]\n",
    "        \"\"\"\n",
    "        assert(type in [\"binary\", \"velocity\"]), \"type must be either binary or velocity\"\n",
    "        \n",
    "        ppr_midi = pypianoroll.read(self.filepath, resolution=resolution)\n",
    "        if type == \"binary\":\n",
    "            ppr_midi.binarize()\n",
    "        piano_roll = ppr_midi.tracks[0].pianoroll.astype(int)\n",
    "        piano_roll = np.swapaxes(piano_roll,0,1)\n",
    "        piano_roll = torch.from_numpy(piano_roll)\n",
    "        piano_roll = piano_roll.to(dtype=tensor_type)\n",
    "        return piano_roll\n",
    "\n",
    "    def plot(self, type: str = \"static\") -> None: \n",
    "        pass \n",
    "        # dynamic plot via bokeh using https://github.com/dubreuia/visual_midi\n",
    "        # statis using pypianoroll: https://salu133445.github.io/pypianoroll/visualization.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 80.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "midi_obj = MIDIClip(local_datapath_midi)\n",
    "pr_obj = midi_obj.pianoroll(type=\"velocity\")\n",
    "print(pr_obj[:,0])\n",
    "print(pr_obj.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
